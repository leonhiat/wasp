{
{-# LANGUAGE LambdaCase #-}

-- This file is processed by Happy (https://www.haskell.org/happy/) and generates
-- the module `Wasp.Analyzer.Parser.Parser`

module Wasp.Analyzer.Parser.Parser
  ( parseStatements,
    parseExpression
  ) where

import Wasp.Analyzer.Parser.Lexer
import Wasp.Analyzer.Parser.AST
import Wasp.Analyzer.Parser.Ctx (WithCtx (..), Ctx (..), ctxFromPos, ctxFromRgn)
import Wasp.Analyzer.Parser.Token
import Wasp.Analyzer.Parser.SourcePosition (SourcePosition (..))
import Wasp.Analyzer.Parser.ParseError
import Wasp.Analyzer.Parser.Monad (Parser, ParserState (..))
import Control.Monad.State.Lazy (get)
import Control.Monad.Except (throwError)
}

-- Lines below tell Happy:
--  - to name the main parsing function `parse` when generating it
--  - that input to parser is `Token` type
--  - to call `parseError` when the parser encounters an error
--  - to provide `parseError` with list of expected tokens that would avoid the error
%name parseStatements Stmts
%name parseExpression Expr

%tokentype { Token }
%error { parseError }
%errorhandlertype explist

-- This sets up Happy to use a monadic parser and threaded lexer.
-- This means that parser generated by Happy will request tokens from lexer as it needs them instead of
-- requiring a list of all tokens up front.
-- Both lexer and parser operate in the 'Parser' monad, which can be used to track shared state and errors.
-- Check https://www.haskell.org/happy/doc/html/sec-monads.html#sec-lexers for more details.
%monad { Parser }
%lexer { lexer } { Token { tokenType = TEOF } }

-- This section defines the names that are used in the grammar section to
-- refer to each type of token.
-- NOTE: If you update it, also update the @prettyShowGrammarToken@ function below.
%token
  '('        { Token { tokenType = TLParen } }
  ')'        { Token { tokenType = TRParen } }
  '['        { Token { tokenType = TLSquare } }
  ']'        { Token { tokenType = TRSquare } }
  '{'        { Token { tokenType = TLCurly } }
  '}'        { Token { tokenType = TRCurly } }
  ','        { Token { tokenType = TComma } }
  ':'        { Token { tokenType = TColon } }
  import     { Token { tokenType = TImport } }
  from       { Token { tokenType = TFrom } }
  true       { Token { tokenType = TTrue } }
  false      { Token { tokenType = TFalse } }
  string     { Token { tokenType = TString $$ } }
  int        { Token { tokenType = TInt $$ } }
  double     { Token { tokenType = TDouble $$ } }
  '{='       { Token { tokenType = TLQuote $$ } }
  quoted     { Token { tokenType = TQuoted $$ } }
  '=}'       { Token { tokenType = TRQuote $$ } }
  id         { Token { tokenType = TIdentifier $$ } }

%%
-- Grammar rules

Stmts :: { AST }
  : StmtWithCtx       { AST [$1] }
  | Stmts StmtWithCtx { AST $ astStmts $1 ++ [$2] }

StmtWithCtx :: { WithCtx Stmt }
  : posStart Stmt posEnd { WithCtx (ctxFromRgn $1 $3) $2 }

Stmt :: { Stmt }
  : Decl { $1 }

Decl :: { Stmt }
  : id id ExprWithCtx { Decl $1 $2 $3 }

ExprWithCtx :: { WithCtx Expr }
  : posStart Expr posEnd { WithCtx (ctxFromRgn $1 $3) $2 }

Expr :: { Expr }
  : Dict      { $1 }
  | List      { $1 }
  | Tuple     { $1 }
  | Extimport { $1 }
  | Quoter    { $1 }
  | string    { StringLiteral $1 }
  | int       { IntegerLiteral $1 }
  | double    { DoubleLiteral $1 }
  | true      { BoolLiteral True }
  | false     { BoolLiteral False }
  | id        { Var $1 }

Dict :: { Expr }
  : '{' DictEntries '}'     { Dict $2 }
  | '{' DictEntries ',' '}' { Dict $2 }
  | '{' '}'                 { Dict [] }

DictEntries :: { [(Identifier, WithCtx Expr)] }
  : DictEntry                 { [$1] }
  | DictEntries ',' DictEntry { $1 ++ [$3] }

DictEntry :: { (Identifier, WithCtx Expr) }
  : id ':' ExprWithCtx { ($1, $3) }

List :: { Expr }
  : '[' ListVals ']'     { List $2 }
  | '[' ListVals ',' ']' { List $2 }
  | '[' ']'              { List [] }

ListVals :: { [WithCtx Expr] }
  : ExprWithCtx              { [$1] }
  | ListVals ',' ExprWithCtx { $1 ++ [$3] }

-- We don't allow tuples shorter than 2 elements,
-- since they are not useful + this way we avoid
-- ambiguity between tuple with single element and expression
-- wrapped in parenthesis for purpose of grouping.
Tuple :: { Expr }
  : '(' TupleVals ')'     { Tuple $2 }
  | '(' TupleVals ',' ')' { Tuple $2 }
TupleVals :: { (WithCtx Expr, WithCtx Expr, [WithCtx Expr]) }
  : ExprWithCtx ',' ExprWithCtx { ($1, $3, []) }
  | TupleVals ',' ExprWithCtx   { (\(a, b, c) -> (a, b, c ++ [$3])) $1 }

Extimport :: { Expr }
  : import Name from string { ExtImport $2 $4 }

Name :: { ExtImportName }
  : id         { ExtImportModule $1 }
  | '{' id '}' { ExtImportField $2 }

Quoter :: { Expr }
  : posStart '{=' posEnd Quoted posStart '=}' posEnd
      {% if $2 /= $6
         then throwError $ QuoterDifferentTags (WithCtx (ctxFromRgn $1 $3) $2) (WithCtx (ctxFromRgn $5 $7) $6)
         else return $ Quoter $2 $4
      }
Quoted :: { String }
  : quoted        { $1 }
  | Quoted quoted { $1 ++ $2 }

-- | Special production that returns the start of the next/following token.
-- NOTE(martin): You might wonder why does it use position of the last scanned (therefore *previous*)
-- token to get the position of the token that should be scanned *after* this production?
-- That sounds like it is getting position of one token too early, right? The trick is that Happy
-- always keeps one lookahead token in reserve, so it is actually always one token ahead of what we
-- would expect. Therefore getting the position of the last scanned token actually gives us the position
-- of the token that follows.
posStart :: { SourcePosition }
  : {- empty -} {% (tokenStartPosition . lastScannedToken) `fmap` get }

-- | Special production that returns the end of the previous token.
posEnd :: { SourcePosition }
  : {- empty -} {% (calcTokenEndPos . lastToLastScannedToken) `fmap` get }

{
parseError :: (Token, [String]) -> Parser a
parseError (token, expectedTokens) =
  throwError $ UnexpectedToken token $ prettyShowGrammarToken <$> expectedTokens

-- Input is grammar token name, as defined in %tokens section above (first column),
-- while output is nicer representation of it, ready to be shown around,
-- e.g. in error messages.
prettyShowGrammarToken :: String -> String
prettyShowGrammarToken = \case
  "'('" -> "("
  "')'" -> ")"
  "'['" -> "["
  "']'" -> "]"
  "'{'" -> "{"
  "'}'" -> "}"
  "','" -> ","
  "':'" -> ":"
  "string" -> "<string>"
  "int" -> "<int>"
  "double" -> "<double>"
  "'{='" -> "{=<identifier>"
  "quoted" -> "<quoted>"
  "'=}'" -> "<identifier>=}"
  "id" -> "<identifier>"
  s -> s
}
